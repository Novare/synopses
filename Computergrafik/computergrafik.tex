\documentclass[10pt,a4paper]{article}
\author{Jannik Koch}
\title{Computergrafik}

\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{mathrsfs}
\usepackage{hyperref}

\def\realnumbers{{\rm I\!R}}
\def\polynomials{{\rm I\!P}}

\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\newcommand{\norm}[1]{\lVert#1\rVert}
\renewcommand{\arraystretch}{1.5}

\begin{document}
	\pagenumbering{Roman}
	{\let\newpage\relax\maketitle}
	\tableofcontents
	\newpage
	\pagenumbering{arabic}
	\setcounter{page}{1}

	\section{Bilder, Farbe, Perzeption}
	\subsection{Rasterbilder}
	Rasterbilder als hauptsächlicher Fokus (statt z.B Vektorgrafik)
	\begin{itemize}
		\item Bild ist rechteckiges Pixelgitter endlicher Pixelzahl
		\item Digitaler Framebuffer als Kopie des Monitorbildes
		\item Pixel haben bestimmte Farbtiefe
		\begin{itemize}
			\item Schwarz/Weiß (1 Bit/Pixel), Graustufen (8 Bit/Pixel), True Color (24 Bit/Pixel)
			\item Farbe mit Farbtabelle (lookup table, \glqq LUT\grqq) und High Dynamic Range (3 x 32 Bit Floating Point/Pixel)
			\item Farbe wird i.d.R. durch RGB-Wert (Rot-Grün-Blau) charakterisiert
		\end{itemize}
	\end{itemize}

	\subsection{Bildtransfer zum Display}
	Die Umsetzung eines digitalen Bildes zu einem sichtbaren Bild auf einem Display kann als Transferfunktion f betrachtet werden. Displaycharakteristika beeinflussen diese Darstellung, darunter:
	\begin{itemize}
		\item Maximale Displayhelligkeit $I_{max}$
		\item Minimale Displayhelligkeit $I_{min}$ (Helligkeit eines schwarzen Pixels)
		\item Reflektiertes Umgebungslicht k
	\end{itemize}
	womit sich der erreichbare Kontrast $R_d = \frac{I_{max} + k}{I_{min} + k}$ ergibt. Man benötigt eine Transferfunktion, bei welcher der Unterschied zwischen aufeinanderfolgenden Pixelwerten nicht bemerkbar (unter 2\%) ist, um Color Banding zu vermeiden.

	\subsection{Gamma-Korrektur}
	\textbf{Problem}:\\
	Digitale Pixelwerte befinden sich in einem linearen Raum, d.h. doppelter Wert impliziert doppelte Helligkeit. Displays verhalten sich nicht linear, weshalb die Pixelwerte auf das Display angepasst werden müssen.
	\\\\
	Dieses Displayverhalten wird durch einen Gamma-Wert ($\gamma$) charakterisiert, die entsprechende Korrektur heißt Gamma-Korrektur. Die Intensität wächst nicht proportional zum Farbwert n bei N Schritten, sondern proportional zu $(\frac{n}{N})^{\gamma}$. Zur Gamma-Korrektur wird entsprechend jeder Farbkanal-Wert mit $\frac{1}{\gamma}$ potenziert.

	\subsection{Alpha-Kanal}
	Zusätzlich zu RGB-Farbwerten wird oftmals auch ein Alpha-Kanal gespeichert, dessen Inhalt die Opazität des Pixels ist.

	\subsection{Licht}
	\begin{itemize}
		\item Licht ist elektromagnetische Strahlung mit verschiedenen Charakteristika von Strahlen, Wellen und Teilchen
		\item Licht besitzt eine Wellenlänge $\lambda$, die u.a. eine Spektralfarbe repräsentiert (Lichtfrequenz $v = \frac{c}{\lambda}$)
		\item Sichtbares Licht: $380nm < \lambda < 700nm$
		\item Licht verschiedener Wellenlängen und verschiedener Intensitäten setzen weitere Farben zusammen
		\item \textbf{Metamerismus}: Unterschiedliche Spektren ergeben dieselbe Farbe
	\end{itemize}

	\subsection{Farbräume}
	\textbf{Allgemein}:\\
	Ein \textbf{Farbmodell} ermöglicht die Beschreibung von Farben durch Wertetupel, jedes Farbmodell erzeugt einen \textbf{Farbraum} aller möglichen Farben und diese können durch entsprechende \textbf{Tristimuluswerte} beschrieben werden.

	\begin{itemize}
		\item Jeder Farbeindruck kann mit 3 Grundgrößen beschrieben werden (Graßmannsche Gesetze)
		\item Additive Farbmischung (vgl. RGB-Farbmodell)
		\begin{itemize}
			\item Summe der Tristimuluswerte Rot, Grün und Blau ergibt finalen Farbwert
		\end{itemize}
		\item Subtraktive Farbmischung (vgl. CMY(K)-Farbmodell)
		\begin{itemize}
			\item Statt RGB: Cyan, Magenta, Yellow (und in der Praxis Schwarz als 4. Key-Color, da CMY typischerweise kein Schwarz ergibt)
			\item Differenz der Farbwerte ergibt finalen Farbwert
		\end{itemize}
		\item Weder additiv noch subtraktiv (vgl. HSV-Farbmodell)
		\begin{itemize}
			\item Charakterisierung der finalen Farbe durch Farbton (Hue), Sättigung (Saturation) und Helligkeit (Value)
		\end{itemize}
	\end{itemize}

	\newpage
	\subsection{Farbraumkonversion}
	\textbf{Ziel}: Farbraum zur standardisierten Konversion zwischen Farbräumen.\\\\
	\textbf{Color Matching Funktionen}
		\begin{itemize}
			\item Reproduktion von Spektralfarben durch RGB-Primärfarben
			\item RGB ist kein perfekter Farbraum, manche Spektralfarben sind nicht realisierbar!
		\end{itemize}		
	\textbf{XYZ-Farbraum}
		\begin{itemize}
			\item Beschreibt alle wahrnehmbaren Farben (\glqq Gamut der menschlichen Wahrnehmung\grqq) mit rein positiven Color Matching Funktionen
			\item Primärfarben sind imaginär, übersaturiert und nicht physikalisch realisierbar
			\item Lineare Abbildung $XYZ \Leftrightarrow RGB$, Transformationsmatrix $M$
			\item Problem: $M^{-1}$ enthält negative Werte, XYZ kann auf negative, nicht darstellbare RGB Werte abbilden
		\end{itemize}
	\textbf{xyY-Farbraum}
		\begin{itemize}
			\item Beobachtung: $kX, kY, kZ (k > 0)$ repräsentiert dieselbe Farbe mit unterschiedlicher Intensität
			\item Idee: Normalisierung auf der $X + Y + Z = 1$ Ebene, daraufhin Projektion auf die XY-Ebene (z weglassen)
			\item Ergebnis: Weiterhin alle Farbtöne und -sättigungen in XY erhalten, neuer xyY Farbraum mit Helligkeit Y und Farbe/Chromatizität xy
		\end{itemize}

	\newpage
	\section{Raytracing}

	\subsection{Grundlagen}
	\begin{itemize}
		\item Bildsynthese durch Simulation des Lichttransports
		\item System ähnlich einer Lochkamera, definiert durch Position, Blickrichtung und vertikaler Orientierung (up-Vektor)
		\item Emittieren von \glqq Lichtstrahlen\grqq\ durch jeden Pixel, zurückverfolgen von der Kamera aus
		\item Prüfen auf Intersektion mit vorhandener Geometrie; sollte eine Intersektion gefunden werden:
			\begin{itemize}
				\item Wähle das getroffene Objekt und dessen Material-Eigenschaften $\Rightarrow$ Shading-Berechnungen
				\item ggf. Verfolgen von weiteren Strahlen ab einer Intersektion (z.B bei spiegelndem Material)
			\end{itemize}
	\end{itemize}

	\subsection{Ray Generation - Mathematische Aspekte}
		\begin{itemize}
			\item Strahl wird durch eine Startposition und eine normierte Richtung modelliert, die um $t \in \realnumbers$ skaliert wird
			\item Allgemein für einen Strahl $r$: $r = e + t * d$ mit der Startposition e und der Richtung d
			\item Bei der Suche nach einem Schnittpunkt wird i.d.R. ein passendes t ausgerechnet, sodass r auf den Schnittpunkt zeigt
		\end{itemize}

	\subsubsection{Baryzentrische Koordinaten}
		Annahme:
		\begin{itemize}
			\item Es existieren k Punkte $P_1, ..., P_k \in \realnumbers^n, k \leq n + 1$
			\item Existiert dann ein Punkt Q der Form $Q = \lambda_1P_1 + \lambda_2P_2 + ... + \lambda_kP_k, \lambda_1 + \lambda_2 + ... + \lambda_k = 1$ (\glqq Affinkombination\grqq)
		\end{itemize}

		Dann definiert man $(\lambda_1, \lambda_2, ..., \lambda_k)$ als die baryzentrischen Koordinaten von Q bzgl. der Basispunkte $P_1, ..., P_k$. Hiermit lässt sich z.B ein Punkt innerhalb eines Dreiecks anhand der Eckpunkte beschreiben (z.B um zu testen ob ein Punkt in einem Dreieck liegt).

	\newpage
	\subsection{Ray Casting - Schnittpunktberechnung}
	\subsubsection{Strahl-Kugel}
		\begin{itemize}
			\item Implizite Darstellung einer Kugel: $|x - c|^2 - r^2 = 0$ mit Radius r und Mittelpunkt c
			\item Damit lassen sich Werte für $t_{1,2}$ (vgl. Mathematische Aspekte) anhand der Mitternachtsformel berechnen, wenn man die Variablen folgendermaßen wählt
			\begin{itemize}
				\item $a = d * d$
				\item $b = 2d * (e - c)$
				\item $c = (e - c) * (e - c) - r^2$
			\end{itemize}
			\item Kein Schnitt: Diskriminante kleiner 0
			\item Kugel wird gestriffen: Beide t-Werte sind identisch
			\item Sonst: Kugelschnitt, zwei verschiedene t-Werte
			\item Hinweis: Nur $t > 0$ sind relevant!
		\end{itemize}

	\subsubsection{Strahl-Ebene}
		\begin{itemize}
			\item Implizite Darstellung einer Ebene: $x * n - d_U = 0$ mit dem Normalenvektor n und dem Abstand vom Ursprung $d_U$
			\item Damit lassen sich Werte für $t$ (vgl. Mathematische Aspekte) anhand der Formel $t = \frac{d_U - e * n}{d * n}$
			\item Achtung: Ist der Nenner $d * n = 0$ sind Strahl und Ebene parallel!
			\item Hinweis: Nur $t > 0$ sind relevant!
		\end{itemize}

	\subsubsection{Strahl-Dreieck}
		\begin{itemize}
			\item Baryzentrische Darstellung eines Punktes in einem Dreieck bestehend aus Punkten $P_1, P_2, P_3: Q = P_1 + \lambda_2(P_2 - P_1) + \lambda_3(P_3 - P_1)$
			\item Anmerkung: $\lambda_1$ ist kein Faktor, die baryzentrischen Koordinaten spannen quasi ein schiefwinkliges Koordinatensystem auf mit dem Ursprung $P_1$
			\item Damit lassen sich Werte für $t$ (vgl. Mathematische Aspekte) durch Lösen der Gleichung $e + t * d = P_1 + \lambda_2(P_2 - P_1) + \lambda_3(P_3 - P_1)$ nach t finden
			\item Achtung: Ist die Gleichung lösbar, so liegt der Schnittpunkt \textbf{in der Ebene des Dreiecks}, damit der Schnittpunkt im Dreieck liegt muss gelten: $\lambda_2, \lambda_3 \geq 0$ und $\lambda_2 + \lambda_3 \leq 1$
			\item Hinweis: Nur $t > 0$ sind relevant!
		\end{itemize}

	\subsection{Shading}
	\begin{itemize}
		\item Wörtlich "Schattierung"
		\item Simulation von Oberflächeneigenschaften
		\item Ermöglicht realistische Tiefenwahrnehmung
	\end{itemize}

	\subsubsection{Materialien}
	\begin{itemize}
		\item Beschreibt Oberflächeneigenschaften
		\item Dadurch: Einfluss auf die Reaktion bei Lichteinfall
		\begin{itemize}
			\item Mattes Material wirkt in erster Linie diffus (keine klare Spiegelung, sehr weich, Licht wird in viele Richtungen gestreut)
			\item Glänzendes/Imperfekt spiegelndes Material besitzt weiche, verschwommene Spiegelungen (\glqq glossy\grqq, zwischen diffus und spekular)
			\item Perfekt spiegelndes Material spiegelt ähnlich wie ein gewöhnlicher Spiegel (\glqq specular\grqq, kaum Streuung)
		\end{itemize}
		\item Reflexionen beschreibt man durch Bidirektionale Reflektanzverteilungsfunktionen (BRDF)
		\begin{itemize}
			\item Generiert durch reale Materialproben sowie Modelle aus Physik und Phänomenologie
			\item Beschreibt Verhältnis von einfallendem zu ausfallendem Licht
			\item Erweiterung auf Transmission (ins Material eindringendes Licht): Bidirectional Transmission Distribution Function (BTDF)
			\item BRDF + BTDF = BSDF (Bidirectional Scattering Distribution Function)
		\end{itemize}
	\end{itemize}

	\subsubsection{Phong-Beleuchtungsmodell}
	\begin{itemize}
		\item Phänomenologisches Modell, modelliert Beleuchtung anhand dreier Komponenten, die aufsummiert den Lichteinfluss ergeben
		\begin{itemize}
			\item Ambient: Grundhelligkeit durch indirekte Beleuchtung
			\item Diffus: Grobe Beleuchtung nach dem Lambertschen Gesetz (beschreibt die Intensitätsabschwächung je nach Material)
			\item Spekular: Imperfekte Spiegelung, \glqq Highlights\grqq
		\end{itemize}
		\item Ambientes Licht ist grundsätzlich immer vorhanden
		\item Diffuses Licht ergibt sich aus dem diffusen Materialfaktor, der Lichtintensität und dem Punktprodukt von Lichtrichtung und Oberflächennormale
		\item Spekulares Licht ergibt sich aus dem spekularen Materialfaktor, der Lichtintensität und dem Punktprodukt von Lichtreflektionsrichtung und Blickrichtung der Kamera hoch \glqq Phong-Exponent\grqq\ n
		\item Die Lichtintensität nimmt mit zunehmender Entfernung zur Lichtquelle ab!
		\item In der Regel werden die Punktprodukte auf 0 und größer \glqq geclampt\grqq, damit z.B Licht von der Rückseite nicht die Vorderseite beleuchtet
	\end{itemize}

	\subsection{Schattierung von Dreiecksnetzen}
	\begin{itemize}
		\item Objekt soll kantig erscheinen $\Rightarrow$ jedes Dreieck besitzt eine Normale, die für das Shading des kompletten Dreiecks genutzt wird
		\item Objekt soll glatt erscheinen $\Rightarrow$ Interpolation; berechne gewichtete Summe der Normalen angrenzender Dreiecke für jeden Pixel
	\end{itemize}

	\subsection{Sekundärstrahlen}
	\begin{itemize}
		\item Sekundärstrahlen für Reflexion:
			\begin{itemize}
				\item z.B Spiegelnde Metallkugel
				\item Bei Intersektion: Trace einen Reflexionsstrahl in die Reflexionsrichtung ab der Position $\epsilon$ Längeneinheiten vor der Intersektion (Vermeidung von erneutem Schneiden derselben Oberfläche) und addiere die resultierende Farbe gewichtet hinzu
			\end{itemize}
		\item Sekundärstrahlen für Transmission:
			\begin{itemize}
				\item z.B Durchsichtige Glaskugel
				\item Bei Intersektion: Trace einen Transmissionsstrahl in die Transmissionsrichtung $\epsilon$ Längeneinheiten von der zweiten Intersektion der Kugel entfernt (Vermeidung von erneutem Schneiden derselben Oberfläche) und addiere die resultierende Farbe gewichtet hinzu
			\end{itemize}
	\end{itemize}

	\subsection{Aliasing}
	\begin{itemize}
		\item Problem: Scharfe, stufige Kanten (\glqq jaggies\grqq), da nur grob abgetastet wird
		\item Lösung: Anti-Aliasing
		\begin{itemize}
			\item Überabtastung (mehrfaches Abtasten desselben Pixels mit leichten Offsets vom Pixelzentrum), dann gewichtete Summe für den Farbwert wählen
			\item Performance-intensiv! Für jeden Pixel müssen nun mehrere Strahlen verfolgt werden, u.U. mit Sekundärstrahlen
		\end{itemize}
	\end{itemize}

	\newpage
	\section{Transformationen}
	\begin{itemize}
		\item Transformationen bilden einen Punkt x auf einen Punkt x' ab
		\item Lineare Transformationen sind Abbildungen mit Transformationsmatrizen $A \in \realnumbers^{mxn}$
		\item Bekannte Transformationen: Translation (Verschiebung), Rotation, uniforme/isotrope Skalierung
		\item Transformationen können durch Multiplikation der Transformationsmatrizen kombiniert werden, hierbei macht die Reihenfolge \textbf{einen Unterschied}; die Transformationen werden \textbf{von rechts nach links angewandt}
		\item Die inverse Transformatinsmatrix führt die entsprechende inverse Transformation durch (Ausnahme: Skalierung um Faktor 0)
	\end{itemize}

	\subsection{Affiner Raum}
	\begin{itemize}
		\item Abbildungen, die teilverhältnistreu sind und parallele Linien erhalten, nennt man \textbf{affin}
		\item Abbildungen, die Geraden auf Geraden abbilden, nennt man \textbf{projektiv}
		\item Alle affinen Abbildungen sind projektive Abbildungen
		\item Identität, Translation, Rotation, (nicht zwingend isotrope) Skalierung, Spiegelung, Scherung sind affine Abbildungen/Transformationen
	\end{itemize}

	\subsection{Homogene Koordinaten}
		\begin{itemize}
			\item Bisher: Zum Beschreiben eines n-dimensionalen Körpers nutzen wir einen n-dimensionalen Raum (z.B einen dreidimensionalen Raum für einen Würfel)
			\item Problem: Parallele Geraden im affinen Raum schneiden sich nicht, bei einer Projektion aber schon
			\item Lösung: Ergänze zusätzliche Dimension zur Formalisierung
			\item \textbf{Homogenisierung von Ortsvektoren}: $(x, y, z)_{3D} \rightarrow (x', y', z', w)_h$ sodass $(\frac{x}{w}, \frac{y}{w}, \frac{z}{w}) = (x, y, z)$ (einfachste Homogenisierung: wähle $x' = x, y' = y, z' = z, w = 1$)
			\item \textbf{Homogenisierung von Richtungsvektoren}: $(x, y, z)_{3D} \rightarrow (x, y, z, w)_h$ mit $w = 0$
			\item \textbf{Dehomogenisierung von Ortsvektoren}: $(x, y, z, w)_h \rightarrow (\frac{x}{w}, \frac{y}{w}, \frac{z}{w})$
		\end{itemize}

	\subsection{Transformation von Normalen}
	\begin{itemize}
		\item Normalen sind Bivektoren, d.h. sie stehen senkrecht auf der Tangentialfläche und sind nicht durch Differenz zweier Ortsvektoren definiert
		\item Lineare und affine Transformationen sind nicht winkeltreu $\rightarrow$ Normalen können nicht einfach mittransformiert werden
		\item \textbf{Stattdessen}: Nicht Normalenvektor, sondern Tangentenebene zur Normale transformieren; praktisch gesehen: transformiere Normalenvektor mit transponiertem Inversen der Transformationsmatrix M des Modells: $N' = (M^{-1})^T N$
	\end{itemize}

	\newpage
	\subsection{Translation}
	Translation funktioniert nur mit homogenisierten Koordinaten. Zur Translation um den Vektor $(t_x, t_y)$ bzw. $(t_x, t_y, t_z):$
	\begin{center}
		$A_{2D_h} = \begin{pmatrix} 1 & 0 & t_x\\0 & 1 & t_y \\ 0 & 0 & 1\end{pmatrix}$\hspace*{1cm}
		$A_{3D_h} = \begin{pmatrix} 1 & 0 & 0 & t_x\\0 & 1 & 0 & t_y\\0 & 0 & 1 & t_z \\ 0 & 0 & 0 & 1\end{pmatrix}$
	\end{center}

	\subsection{Rotation}
	Sei $\phi$ im Folgenden der Rotationswinkel.\\\\
	\textit{Anmerkung:\\Die folgenden Matrizen beschreiben sog. Euler-Rotationen. Diese sind anfällig für Probleme wie den Gimbal Lock, jedoch intuitiver als Quaternions, welche in der Vorlesung nicht besprochen werden.}\\\\
	\textbf{Zweidimensional (Rotation um die y-Achse)}:
	\begin{center}
		$A_{2D}(\phi) = \begin{pmatrix}cos \phi & -sin \phi \\ sin \phi & cos \phi\end{pmatrix}$\hspace*{0.5cm}
		$A_{2D_h}(\phi) = \begin{pmatrix}cos \phi & -sin \phi & 0 \\ sin \phi & cos \phi & 0 \\ 0 & 0 & 1\end{pmatrix}$\vspace*{0.25cm}
	\end{center}
	\textbf{Dreidimensional (Rotation um die x-, y- oder z-Achse)}:
	\begin{center}
		$A_{x}(\phi) = \begin{pmatrix}1 & 0 & 0\\ 0 & cos \phi & -sin \phi\\ 0 & sin \phi & cos \phi \end{pmatrix}$\hfill
		$A_{y}(\phi) = \begin{pmatrix}cos \phi & 0 & sin \phi\\0 & 1 & 0\\-sin \phi & 0 & cos \phi\end{pmatrix}$\hfill
		$A_{z}(\phi) = \begin{pmatrix}cos \phi & -sin \phi & 0\\ sin \phi & cos \phi & 0 \\ 0 & 0 & 1\end{pmatrix}$\vspace*{0.25cm}\\
	\end{center}
	\textbf{Dreidimensional, homogenisiert (Rotation um die x-, y- oder z-Achse)}:\\\\
	$A_{x}(\phi) = \begin{pmatrix}1 & 0 & 0 & 0\\ 0 & cos \phi & -sin \phi& 0\\ 0 & sin \phi & cos \phi & 0\\ 0 & 0 & 0 & 1\end{pmatrix}$
	$A_{y}(\phi) = \begin{pmatrix}cos \phi & 0 & sin \phi& 0\\0 & 1 & 0& 0\\-sin \phi & 0 & cos \phi & 0\\ 0 & 0 & 0 & 1\end{pmatrix}$
	$A_{z}(\phi) = \begin{pmatrix}cos \phi & -sin \phi & 0& 0\\ sin \phi & cos \phi & 0 & 0\\ 0 & 0 & 1 & 0\\ 0 & 0 & 0 & 1\end{pmatrix}$

	\newpage
	\subsection{Skalierung}
	Sei $(s_x, s_y)$ bzw. $(s_x, s_y, s_z)$ im Folgenden der Vektor, der entlang der entsprechenden Achsen um den entsprechenden Betrag skaliert.

	\begin{center}
		$A_{2D} = \begin{pmatrix} s_x & 0\\0 & s_y\end{pmatrix}$\hfill
		$A_{2D_h} = \begin{pmatrix} s_x & 0 & 0\\0 & s_y & 0 \\ 0 & 0 & 1\end{pmatrix}$\hfill
		$A_{3D} = \begin{pmatrix} s_x & 0 & 0\\0 & s_y & 0\\0 & 0 & s_z\end{pmatrix}$\hfill
		$A_{3D_h} = \begin{pmatrix} s_x & 0 & 0 & 0\\0 & s_y & 0 & 0\\0 & 0 & s_z & 0 \\ 0 & 0 & 0 & 1\end{pmatrix}$\hfill
	\end{center}

	\subsection{Scherung/Transvektion}
	\textbf{Zweidimensional}:
	\begin{center}
		$A_{x} = \begin{pmatrix}1 & s \\ 0 & 1\end{pmatrix}$\hfill
		$A_{x_h} = \begin{pmatrix}1 & s & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}$\hfill
		$A_{y} = \begin{pmatrix}1 & 0 \\ s & 1\end{pmatrix}$\hfill
		$A_{y_h} = \begin{pmatrix}1 & 0 & 0 \\ s & 1 & 0 \\ 0 & 0 & 1\end{pmatrix}$\hfill
	\end{center}	

	\subsection{Spiegelung}
	Spiegelungen sind realisierbar als negative Skalierungen.\\\textbf{Bsp.:} Spiegelung an der x-Achse ist eine x-Skalierung um den Faktor -1.

	\subsection{Koordinatensysteme}
	\begin{itemize}
		\item Objekte innerhalb einer Szene werden in ihrem eigenen \textbf{Objektkoordinatensystem} angegeben
		\item Durch eine Modelltransformation (Translation, Skalierung, ...) werden Objekte im \textbf{Weltkoordinatensystem} platziert
		\item Anhand der Kamera, aus der die Szene betrachtet wird, erfolgt dann die Transformation in das \textbf{Kamerakoordinatensystem}
	\end{itemize}

	\subsection{Szenengraphen}
	\begin{itemize}
		\item Modelltransformationen sind üblicherweise zusammengesetzte Transformationen
		\item Transformation von Geometrie ist oftmals leichter relativ zu anderer Geometrie definierbar (z.B Lenkrad relativ zu Auto-Modell)
		\item \textbf{Szenengraph}: Gerichteter azyklischer Graph mit Objekten als Knoten, die jeweils relativ zu ihren Eltern-Knoten transformiert werden müssen
		\item \textbf{Matrix-Stack}: Stack auf dem Transformationen gespeichert werden, sodass diese leicht wiederverwendet werden können
	\end{itemize}

	\newpage
	\section{Texturen}

	\newpage
	\section{Räumliche Datenstrukturen}

	\newpage
	\section{Rasterisierung und Projektion}

	\newpage
	\section{OpenGL und Grafik-Hardware}
\end{document}
